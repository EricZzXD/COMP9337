{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 7 - Using Machine Learning for Intrusion Detection\n",
    "\n",
    "This Lab exercise will guide you through an example of using a machine learning (ML) algorithm to train a model for intrusion detection. You have been provided with this Notebook with markdown explanations & code used in this example, and a custom dataset that has been extracted from the NBaIoT dataset provided by UCI machine learning repository (https://archive.ics.uci.edu/ml/datasets/detection_of_IoT_botnet_attacks_N_BaIoT).\n",
    "\n",
    "The provided dataset has labelled samples from benign traffic generated by a security camera (SimpleHome XCs7-1003-WHT) as well as traces when this camera is infected with Mirai botnet to launch a TCP SYN flooding attack. There are 115 features with one target class in the dataset. Details are in the following paper. \n",
    "\n",
    "[1] Y. Meidan, M. Bohadana, Y. Mathov, Y. Mirsky, D. Breitenbacher, A. Shabtai, and Y. Elovici \"N-BaIoT: Network-based Detection of IoT Botnet Attacks Using Deep Autoencoders\", IEEE Pervasive Computing, Special Issue - Securing the IoT (July/Sep 2018).\n",
    "\n",
    "Attribute/Features Information:\n",
    "The following describes each of the features headers:\n",
    "\n",
    "- Stream aggregation:\n",
    "   - H: (\"Source IP\" in N-BaIoT paper) Stats summarizing the recent traffic from this packet's host (IP)\n",
    "   - MI: (\"Source MAC-IP\" in N-BaIoT paper) Stats summarizing the recent traffic from this packet's host (IP + MAC)\n",
    "   - HH: (\"Channel\" in N-BaIoT paper) Stats summarizing the recent traffic going from this packet's host (IP) to the packet's destination host.\n",
    "   - HH_jit: (\"Channel jitter\" in N-BaIoT paper) Stats summarizing the jitter of the traffic going from this packet's host (IP) to the packet's destination host.\n",
    "   - HpHp: (\"Socket\" in N-BaIoT paper) Stats summarizing the recent traffic going from this packet's host+port (IP) to the packet's destination host+port. Example 192.168.4.2:1242 -> 192.168.4.12:80\n",
    "- Time-frame (The decay factor Lambda used in the damped window): \n",
    "    - How much recent history of the stream is capture in these statistics (L5, L3, L1, L0.1 and L0.01)\n",
    "- The statistics extracted from the packet stream:\n",
    "   - weight: The weight of the stream (can be viewed as the number of items observed in recent history)\n",
    "   - mean: ...\n",
    "   - std: ...\n",
    "   - radius: The root squared sum of the two streams' variances\n",
    "   - magnitude: The root squared sum of the two streams' means \n",
    "   - cov: An approximated covariance between two streams\n",
    "   - pcc: An approximated correlation coefficient between two streams\n",
    "\n",
    "\n",
    "If you are interested in learning how these features have been extracted from the raw pcap (TCPDump or Wireshark captures), read the following paper. \n",
    "\n",
    "[2] Y. Mirsky, T. Doitshman, Y. Elovici & A. Shabtai 2018, \"Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection\", in Network and Distributed System Security (NDSS) Symposium, San Diego, CA, USA. \n",
    "\n",
    "The example code in this notebook employs a simple supervised machine learning algorithm called K-Nearest Neighbor (k-NN) for classification purposes. The markdown text walks you through the ML pipeline required to train the model on the dataset, and evaluate its performance.  \n",
    "\n",
    "You are required to create another Notebook by using a different ML algorithm called Decision Trees (DT - https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). You are to compare the results from using k-NN and DT on the provided dataset. Submit your DT notebook with narrative text explaining the following:\n",
    "\n",
    "1. Compare the performance of k-NN and DT for the given classification task using accuracy, precision, recall, and latency as the metrics. \n",
    "2. Show the confusion matrix and the RoC curve \n",
    "3. Comment on performance of DT by using different values for hyperparameters (splitter, max_depth, min_samples_split, max_features) and split ratios (train:valid:test = 4:3:3, 3:1:1, 8:1:1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries, Modules and read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np   ### Support for large, multi-dimensional arrays and matrices. Has a large collection of high-level mathematical functions.\n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, plot_roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "\n",
    "dataset = pd.read_csv('FinalDataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a peek at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mirai_SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.995653</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.997390</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>1.999129</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.999913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mirai_SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.984032</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.990403</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>2.996795</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9.090000e-13</td>\n",
       "      <td>2.999679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mirai_SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.952494</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.971399</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>3.990434</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.999042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mirai_SYN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.931439</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9.090000e-13</td>\n",
       "      <td>4.958692</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1.820000e-12</td>\n",
       "      <td>4.986173</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9.090000e-13</td>\n",
       "      <td>4.998615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mirai_SYN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MI_dir_L5_weight  MI_dir_L5_mean  MI_dir_L5_variance  MI_dir_L3_weight  \\\n",
       "0          1.000000            74.0        0.000000e+00          1.000000   \n",
       "1          1.995653            74.0        0.000000e+00          1.997390   \n",
       "2          2.984032            74.0        0.000000e+00          2.990403   \n",
       "3          3.952494            74.0        0.000000e+00          3.971399   \n",
       "4          4.931439            74.0        9.090000e-13          4.958692   \n",
       "\n",
       "   MI_dir_L3_mean  MI_dir_L3_variance  MI_dir_L1_weight  MI_dir_L1_mean  \\\n",
       "0            74.0        0.000000e+00          1.000000            74.0   \n",
       "1            74.0        1.820000e-12          1.999129            74.0   \n",
       "2            74.0        1.820000e-12          2.996795            74.0   \n",
       "3            74.0        1.820000e-12          3.990434            74.0   \n",
       "4            74.0        1.820000e-12          4.986173            74.0   \n",
       "\n",
       "   MI_dir_L1_variance  MI_dir_L0.1_weight  ...  HpHp_L0.1_covariance  \\\n",
       "0        0.000000e+00            1.000000  ...                   0.0   \n",
       "1        0.000000e+00            1.999913  ...                   0.0   \n",
       "2        9.090000e-13            2.999679  ...                   0.0   \n",
       "3        0.000000e+00            3.999042  ...                   0.0   \n",
       "4        9.090000e-13            4.998615  ...                   0.0   \n",
       "\n",
       "   HpHp_L0.1_pcc  HpHp_L0.01_weight  HpHp_L0.01_mean  HpHp_L0.01_std  \\\n",
       "0            0.0                1.0             74.0             0.0   \n",
       "1            0.0                1.0             74.0             0.0   \n",
       "2            0.0                1.0             74.0             0.0   \n",
       "3            0.0                1.0             74.0             0.0   \n",
       "4            0.0                1.0             74.0             0.0   \n",
       "\n",
       "   HpHp_L0.01_magnitude  HpHp_L0.01_radius  HpHp_L0.01_covariance  \\\n",
       "0                  74.0                0.0                    0.0   \n",
       "1                  74.0                0.0                    0.0   \n",
       "2                  74.0                0.0                    0.0   \n",
       "3                  74.0                0.0                    0.0   \n",
       "4                  74.0                0.0                    0.0   \n",
       "\n",
       "   HpHp_L0.01_pcc      Class  \n",
       "0             0.0  Mirai_SYN  \n",
       "1             0.0  Mirai_SYN  \n",
       "2             0.0  Mirai_SYN  \n",
       "3             0.0  Mirai_SYN  \n",
       "4             0.0  Mirai_SYN  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "#gives the first five rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39056 entries, 0 to 39055\n",
      "Columns: 116 entries, MI_dir_L5_weight to Class\n",
      "dtypes: float64(115), object(1)\n",
      "memory usage: 34.6+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()# See the distribution of our target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mirai_SYN    19528\n",
       "Benign       19528\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Class'].value_counts()  #check whether it is a balanced dataset or an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_radius</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>...</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "      <td>39,056.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>70.569</td>\n",
       "      <td>145.774</td>\n",
       "      <td>151.178</td>\n",
       "      <td>113.910</td>\n",
       "      <td>145.738</td>\n",
       "      <td>203.423</td>\n",
       "      <td>330.944</td>\n",
       "      <td>147.771</td>\n",
       "      <td>928.338</td>\n",
       "      <td>3,029.858</td>\n",
       "      <td>...</td>\n",
       "      <td>2,182.203</td>\n",
       "      <td>-24.576</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>5.467</td>\n",
       "      <td>146.028</td>\n",
       "      <td>2.912</td>\n",
       "      <td>191.321</td>\n",
       "      <td>2,759.261</td>\n",
       "      <td>-133.272</td>\n",
       "      <td>-0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72.909</td>\n",
       "      <td>119.313</td>\n",
       "      <td>1,770.355</td>\n",
       "      <td>115.984</td>\n",
       "      <td>119.088</td>\n",
       "      <td>1,982.480</td>\n",
       "      <td>332.315</td>\n",
       "      <td>116.868</td>\n",
       "      <td>2,945.813</td>\n",
       "      <td>3,041.787</td>\n",
       "      <td>...</td>\n",
       "      <td>16,463.431</td>\n",
       "      <td>2,001.900</td>\n",
       "      <td>0.038</td>\n",
       "      <td>15.334</td>\n",
       "      <td>118.702</td>\n",
       "      <td>16.897</td>\n",
       "      <td>179.734</td>\n",
       "      <td>22,582.172</td>\n",
       "      <td>4,793.291</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-37,601.681</td>\n",
       "      <td>-0.587</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-68,855.092</td>\n",
       "      <td>-1.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000</td>\n",
       "      <td>67.488</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>68.537</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.062</td>\n",
       "      <td>70.547</td>\n",
       "      <td>0.107</td>\n",
       "      <td>2.768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21.300</td>\n",
       "      <td>72.242</td>\n",
       "      <td>4.996</td>\n",
       "      <td>21.641</td>\n",
       "      <td>71.610</td>\n",
       "      <td>14.184</td>\n",
       "      <td>22.570</td>\n",
       "      <td>71.586</td>\n",
       "      <td>34.982</td>\n",
       "      <td>49.960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>136.877</td>\n",
       "      <td>330.000</td>\n",
       "      <td>37.087</td>\n",
       "      <td>224.669</td>\n",
       "      <td>330.000</td>\n",
       "      <td>38.027</td>\n",
       "      <td>662.818</td>\n",
       "      <td>329.999</td>\n",
       "      <td>42.857</td>\n",
       "      <td>6,201.298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.275</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>431.490</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>251.405</td>\n",
       "      <td>670.000</td>\n",
       "      <td>83,290.214</td>\n",
       "      <td>354.414</td>\n",
       "      <td>670.000</td>\n",
       "      <td>89,354.113</td>\n",
       "      <td>828.257</td>\n",
       "      <td>669.565</td>\n",
       "      <td>92,557.424</td>\n",
       "      <td>6,546.597</td>\n",
       "      <td>...</td>\n",
       "      <td>480,808.295</td>\n",
       "      <td>69,895.058</td>\n",
       "      <td>0.707</td>\n",
       "      <td>148.749</td>\n",
       "      <td>670.000</td>\n",
       "      <td>220.179</td>\n",
       "      <td>1,265.998</td>\n",
       "      <td>454,622.861</td>\n",
       "      <td>143,864.111</td>\n",
       "      <td>1.299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MI_dir_L5_weight       MI_dir_L5_mean   MI_dir_L5_variance  \\\n",
       "count           39,056.000           39,056.000           39,056.000   \n",
       "mean                70.569              145.774              151.178   \n",
       "std                 72.909              119.313            1,770.355   \n",
       "min                  1.000               60.000                0.000   \n",
       "25%                  1.000               67.488                0.000   \n",
       "50%                 21.300               72.242                4.996   \n",
       "75%                136.877              330.000               37.087   \n",
       "max                251.405              670.000           83,290.214   \n",
       "\n",
       "          MI_dir_L3_weight       MI_dir_L3_mean   MI_dir_L3_variance  \\\n",
       "count           39,056.000           39,056.000           39,056.000   \n",
       "mean               113.910              145.738              203.423   \n",
       "std                115.984              119.088            1,982.480   \n",
       "min                  1.000               60.000                0.000   \n",
       "25%                  1.000               68.537                0.000   \n",
       "50%                 21.641               71.610               14.184   \n",
       "75%                224.669              330.000               38.027   \n",
       "max                354.414              670.000           89,354.113   \n",
       "\n",
       "          MI_dir_L1_weight       MI_dir_L1_mean   MI_dir_L1_variance  \\\n",
       "count           39,056.000           39,056.000           39,056.000   \n",
       "mean               330.944              147.771              928.338   \n",
       "std                332.315              116.868            2,945.813   \n",
       "min                  1.000               60.000                0.000   \n",
       "25%                  1.062               70.547                0.107   \n",
       "50%                 22.570               71.586               34.982   \n",
       "75%                662.818              329.999               42.857   \n",
       "max                828.257              669.565           92,557.424   \n",
       "\n",
       "        MI_dir_L0.1_weight  ...     HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n",
       "count           39,056.000  ...           39,056.000            39,056.000   \n",
       "mean             3,029.858  ...            2,182.203               -24.576   \n",
       "std              3,041.787  ...           16,463.431             2,001.900   \n",
       "min                  1.000  ...                0.000           -37,601.681   \n",
       "25%                  2.768  ...                0.000                 0.000   \n",
       "50%                 49.960  ...                0.000                 0.000   \n",
       "75%              6,201.298  ...                0.000                 0.000   \n",
       "max              6,546.597  ...          480,808.295            69,895.058   \n",
       "\n",
       "             HpHp_L0.1_pcc    HpHp_L0.01_weight      HpHp_L0.01_mean  \\\n",
       "count           39,056.000           39,056.000           39,056.000   \n",
       "mean                -0.000                5.467              146.028   \n",
       "std                  0.038               15.334              118.702   \n",
       "min                 -0.587                1.000               60.000   \n",
       "25%                  0.000                1.000               60.000   \n",
       "50%                  0.000                1.000               74.000   \n",
       "75%                  0.000                6.275              330.000   \n",
       "max                  0.707              148.749              670.000   \n",
       "\n",
       "            HpHp_L0.01_std  HpHp_L0.01_magnitude    HpHp_L0.01_radius  \\\n",
       "count           39,056.000            39,056.000           39,056.000   \n",
       "mean                 2.912               191.321            2,759.261   \n",
       "std                 16.897               179.734           22,582.172   \n",
       "min                  0.000                60.000                0.000   \n",
       "25%                  0.000                74.000                0.000   \n",
       "50%                  0.000                74.000                0.000   \n",
       "75%                  0.000               431.490                0.000   \n",
       "max                220.179             1,265.998          454,622.861   \n",
       "\n",
       "       HpHp_L0.01_covariance       HpHp_L0.01_pcc  \n",
       "count             39,056.000           39,056.000  \n",
       "mean                -133.272               -0.011  \n",
       "std                4,793.291                0.107  \n",
       "min              -68,855.092               -1.138  \n",
       "25%                    0.000                0.000  \n",
       "50%                    0.000                0.000  \n",
       "75%                    0.000                0.000  \n",
       "max              143,864.111                1.299  \n",
       "\n",
       "[8 rows x 115 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get an idea about the actual data distribution\n",
    "pd.options.display.float_format = '{:20,.3f}'.format\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check whether there are null values\n",
    "dataset.columns[dataset.isna().any()].tolist()\n",
    "# dataset.isnull().sum()\n",
    "\n",
    "## Fill any null values with the Mean value of that feature. Should make sure that null is not a acceptable value for that feature.\n",
    "# dataset['MI_dir_L5_weight'].fillna(dataset['MI_dir_L5_weight'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MI_dir_L5_weight         1592\n",
      "MI_dir_L5_mean           1592\n",
      "MI_dir_L5_variance       1592\n",
      "MI_dir_L3_weight         1592\n",
      "MI_dir_L3_mean           1592\n",
      "                         ... \n",
      "HpHp_L0.01_magnitude     1592\n",
      "HpHp_L0.01_radius        1592\n",
      "HpHp_L0.01_covariance    1592\n",
      "HpHp_L0.01_pcc           1592\n",
      "Class                    1592\n",
      "Length: 116, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for duplicates\n",
    "# Select duplicate rows except first occurrence based on all columns\n",
    "duplicates = dataset[dataset.duplicated()]\n",
    "print(duplicates.count())\n",
    "\n",
    "#Keep the first occurance \n",
    "# dataset.duplicated(subset=None, keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, validation, and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset\n",
    "dataset = dataset.reindex(np.random.permutation(dataset.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate Features and Labels\n",
    "features = dataset.drop('Class', axis=1)\n",
    "# features = dataset.iloc[:,50:80] #We can slice the dataframe and test with different feature combinations.\n",
    "labels = dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI_dir_L5_weight</th>\n",
       "      <th>MI_dir_L5_mean</th>\n",
       "      <th>MI_dir_L5_variance</th>\n",
       "      <th>MI_dir_L3_weight</th>\n",
       "      <th>MI_dir_L3_mean</th>\n",
       "      <th>MI_dir_L3_variance</th>\n",
       "      <th>MI_dir_L1_weight</th>\n",
       "      <th>MI_dir_L1_mean</th>\n",
       "      <th>MI_dir_L1_variance</th>\n",
       "      <th>MI_dir_L0.1_weight</th>\n",
       "      <th>...</th>\n",
       "      <th>HpHp_L0.1_radius</th>\n",
       "      <th>HpHp_L0.1_covariance</th>\n",
       "      <th>HpHp_L0.1_pcc</th>\n",
       "      <th>HpHp_L0.01_weight</th>\n",
       "      <th>HpHp_L0.01_mean</th>\n",
       "      <th>HpHp_L0.01_std</th>\n",
       "      <th>HpHp_L0.01_magnitude</th>\n",
       "      <th>HpHp_L0.01_radius</th>\n",
       "      <th>HpHp_L0.01_covariance</th>\n",
       "      <th>HpHp_L0.01_pcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33413</th>\n",
       "      <td>2.000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2.748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.272</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>431.490</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5595</th>\n",
       "      <td>176.147</td>\n",
       "      <td>66.881</td>\n",
       "      <td>52.353</td>\n",
       "      <td>277.886</td>\n",
       "      <td>68.041</td>\n",
       "      <td>50.814</td>\n",
       "      <td>754.350</td>\n",
       "      <td>69.791</td>\n",
       "      <td>43.638</td>\n",
       "      <td>6,004.758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21285</th>\n",
       "      <td>1.000</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1.000</td>\n",
       "      <td>60.016</td>\n",
       "      <td>4.378</td>\n",
       "      <td>1.062</td>\n",
       "      <td>75.803</td>\n",
       "      <td>4,017.081</td>\n",
       "      <td>2.955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.280</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>84.853</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34364</th>\n",
       "      <td>1.000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1.741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.278</td>\n",
       "      <td>330.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>431.490</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9383</th>\n",
       "      <td>117.227</td>\n",
       "      <td>72.260</td>\n",
       "      <td>21.331</td>\n",
       "      <td>195.957</td>\n",
       "      <td>72.343</td>\n",
       "      <td>20.453</td>\n",
       "      <td>591.778</td>\n",
       "      <td>71.390</td>\n",
       "      <td>29.906</td>\n",
       "      <td>6,161.883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MI_dir_L5_weight       MI_dir_L5_mean   MI_dir_L5_variance  \\\n",
       "33413                2.000              330.000                0.000   \n",
       "5595               176.147               66.881               52.353   \n",
       "21285                1.000               60.000                0.004   \n",
       "34364                1.000              330.000                0.000   \n",
       "9383               117.227               72.260               21.331   \n",
       "\n",
       "          MI_dir_L3_weight       MI_dir_L3_mean   MI_dir_L3_variance  \\\n",
       "33413                2.000              330.000                0.000   \n",
       "5595               277.886               68.041               50.814   \n",
       "21285                1.000               60.016                4.378   \n",
       "34364                1.000              330.000                0.000   \n",
       "9383               195.957               72.343               20.453   \n",
       "\n",
       "          MI_dir_L1_weight       MI_dir_L1_mean   MI_dir_L1_variance  \\\n",
       "33413                2.000              330.000                0.040   \n",
       "5595               754.350               69.791               43.638   \n",
       "21285                1.062               75.803            4,017.081   \n",
       "34364                1.000              330.000                0.070   \n",
       "9383               591.778               71.390               29.906   \n",
       "\n",
       "        MI_dir_L0.1_weight  ...     HpHp_L0.1_radius  HpHp_L0.1_covariance  \\\n",
       "33413                2.748  ...                0.000                 0.000   \n",
       "5595             6,004.758  ...                0.000                 0.000   \n",
       "21285                2.955  ...                0.000                 0.000   \n",
       "34364                1.741  ...                0.000                -0.000   \n",
       "9383             6,161.883  ...                0.000                 0.000   \n",
       "\n",
       "             HpHp_L0.1_pcc    HpHp_L0.01_weight      HpHp_L0.01_mean  \\\n",
       "33413                0.000                6.272              330.000   \n",
       "5595                 0.000                1.000               74.000   \n",
       "21285                0.000                6.280               60.000   \n",
       "34364                0.000                6.278              330.000   \n",
       "9383                 0.000                1.000               74.000   \n",
       "\n",
       "            HpHp_L0.01_std  HpHp_L0.01_magnitude    HpHp_L0.01_radius  \\\n",
       "33413                0.000               431.490                0.000   \n",
       "5595                 0.000                74.000                0.000   \n",
       "21285                0.000                84.853                0.000   \n",
       "34364                0.000               431.490                0.000   \n",
       "9383                 0.000                74.000                0.000   \n",
       "\n",
       "       HpHp_L0.01_covariance       HpHp_L0.01_pcc  \n",
       "33413                 -0.000               -0.000  \n",
       "5595                   0.000                0.000  \n",
       "21285                  0.000                0.000  \n",
       "34364                  0.000                0.000  \n",
       "9383                   0.000                0.000  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33413       Benign\n",
       "5595     Mirai_SYN\n",
       "21285       Benign\n",
       "34364       Benign\n",
       "9383     Mirai_SYN\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset in to Training, Validation and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and evaluate a KNN model with default values and use 5-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign' 'Benign' 'Benign' ... 'Mirai_SYN' 'Benign' 'Mirai_SYN']\n",
      "Training Latency: 22.0ms\n"
     ]
    }
   ],
   "source": [
    "#First lets try to make a model and evaluate it\n",
    "knn = KNeighborsClassifier()\n",
    "start =time()\n",
    "knn0 = knn.fit(X_train, y_train)\n",
    "end = time()\n",
    "y_pred0 = knn0.predict(X_val)\n",
    "print(y_pred0)\n",
    "print('Training Latency: {}ms'.format(round((end - start)*1000, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance evaluation, we use the following 3 standard metrics; Accuracy, TruePositive Rate (TPR)/ Recall, Precision, and which are defined as follows.\n",
    "\n",
    "1. Accuracy = Number of correct predictions / Total Number of samples<br>\n",
    "$(TP + TN)/(TP + TN + FP + FN)$; <br>\n",
    "2. TPR/Recall = Number of True positives / Number of Actual Positives <br>\n",
    "$TP / (TP + FN)$;<br>\n",
    "3. Precision = Number of True Positives / Number of All Positives <br>\n",
    "$TP/ (TP + FP)$;<br>\n",
    "\n",
    "where $TP$, $FN$, $FP$, and $TN$ denotes True Positives, False Negatives, False Positives, and True Negatives respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model using Accuracy, Precision, Recall, Latency\n",
    "def evaluate_model(model, features, labels):\n",
    "    start = time()\n",
    "    pred = model.predict(features)\n",
    "    end = time()\n",
    "    accuracy = round(accuracy_score(labels, pred), 3)\n",
    "    precision = round(precision_score(labels, pred, pos_label='Mirai_SYN'), 3)  # True Positives/All Positives (TP+FN)\n",
    "    recall = round(recall_score(labels, pred, pos_label='Mirai_SYN'), 3)  # True positives/ Actual positives (TP+FN)\n",
    "      \n",
    "    print('n_neighbors: {} -- Accuracy: {} / Precision: {} / Recall: {} / Prediction Latency: {}ms'.format(model.n_neighbors,\n",
    "                                                                                   accuracy,\n",
    "                                                                                   precision,\n",
    "                                                                                   recall,\n",
    "                                                                                   round((end - start)*1000, 1)))\n",
    "    confusionMatrix = confusion_matrix(labels, pred)\n",
    "    print(confusionMatrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 5 -- Accuracy: 0.999 / Precision: 1.0 / Recall: 0.998 / Prediction Latency: 2225.5ms\n",
      "[[3886    1]\n",
      " [   9 3916]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(knn0, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.9991038133553992, Std: 0.00034141529182183256\n"
     ]
    }
   ],
   "source": [
    "##Using Cross Validation\n",
    "scores = cross_val_score(knn, X_train, y_train.values.ravel(), cv=5)\n",
    "print ('Mean: {}, Std: {}'.format(scores.mean(),scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying with different hyperparameters\n",
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn1.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn5.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "knn10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn10.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate models on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1 -- Accuracy: 0.999 / Precision: 1.0 / Recall: 0.999 / Prediction Latency: 1468.0ms\n",
      "[[3887    0]\n",
      " [   5 3920]]\n",
      "n_neighbors: 5 -- Accuracy: 0.999 / Precision: 1.0 / Recall: 0.998 / Prediction Latency: 2255.7ms\n",
      "[[3886    1]\n",
      " [   9 3916]]\n",
      "n_neighbors: 10 -- Accuracy: 0.998 / Precision: 1.0 / Recall: 0.996 / Prediction Latency: 2236.0ms\n",
      "[[3887    0]\n",
      " [  14 3911]]\n"
     ]
    }
   ],
   "source": [
    "for mdl in [knn1, knn5, knn10]:\n",
    "    evaluate_model(mdl, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like KNN performs best with n_neighbors set to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1 -- Accuracy: 1.0 / Precision: 1.0 / Recall: 1.0 / Prediction Latency: 1468.8ms\n",
      "[[3865    0]\n",
      " [   1 3945]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(knn1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Grid Search Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the previous method to build models with different hyperparameters, we can use the $GridSearchCV$ function in Scikit Learn to train models with different hyperparameter combinations while using cross validation techniques as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'n_neighbors': 1}\n",
      "\n",
      "1.0 (+/-0.0) for {'n_neighbors': 1}\n",
      "0.999 (+/-0.001) for {'n_neighbors': 5}\n",
      "0.999 (+/-0.0) for {'n_neighbors': 10}\n"
     ]
    }
   ],
   "source": [
    "#Using Grid Search CV\n",
    "knnGridCV = KNeighborsClassifier()\n",
    "parameters = {\n",
    "    'n_neighbors' : [1,5,10]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(knnGridCV, parameters, cv=5)\n",
    "cv.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1 -- Accuracy: 1.0 / Precision: 1.0 / Recall: 1.0 / Prediction Latency: 1470.5ms\n",
      "[[3865    0]\n",
      " [   1 3945]]\n"
     ]
    }
   ],
   "source": [
    "#Get the model with the best hyperparameters and evaluate on the Test set. \n",
    "#Also, if there are lots of models you can select the best ones and evaluate them on the validation set to select the best one.\n",
    "evaluate_model(cv.best_estimator_, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\unsw - master of it\\in progress\\comp9334 - capacity planning of computer systems and networks\\assignment\\lab 6\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_roc_curve is deprecated; Function :func:`plot_roc_curve` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: :meth:`sklearn.metric.RocCurveDisplay.from_predictions` or :meth:`sklearn.metric.RocCurveDisplay.from_estimator`.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "plot_roc_curve(cv.best_estimator_, X_test, y_test)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
